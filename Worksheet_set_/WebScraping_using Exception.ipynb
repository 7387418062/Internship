{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a76a73",
   "metadata": {},
   "source": [
    "# 1. Write a python program which searches all the product under a particular product from www.amazon.in. The\n",
    "product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for\n",
    "guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f7fd3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4f47148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "32e3d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "943a5ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guitar\n"
     ]
    }
   ],
   "source": [
    "search_bar = driver.find_element(By.ID,'twotabsearchtextbox')\n",
    "search_for = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d6366f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar.send_keys(search_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "075315d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element(By.ID,'nav-search-submit-button')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370201ea",
   "metadata": {},
   "source": [
    "# 2. In the above question, now scrape the following details of each product listed in first 3 pages of your search\n",
    "results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then\n",
    "scrape all the products available under that product name. Details to be scraped are: \"Brand\n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and\n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "288df98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.amazon.in/sspa/click?ie=UTF8&spc=MTo1NjIyODUyNDg2OTI3MTcwOjE3MTg3OTkyNzQ6c3BfYXRmOjMwMDAxNTUzNzk3OTIzMjo6MDo6&url=%2FKadence-Frontier-Acoustic-Guitar-Strings%2Fdp%2FB078GTJP5Y%2Fref%3Dsr_1_1_sspa%3Fdib%3DeyJ2IjoiMSJ9.H_dE0w8OHcmESxseNpLSv2KJQzpOhYBPQuvVEAHBow0jXCjOKKkLHAIV5Vm788nEVgS7X-PNTDnqOJ6rU8gbTjbKIEU0GlkBJardajM_Nxul_zYMIpU6j37pfjHvh5ZHPVH6i9Nm97xp1FmrlYL3tKwNwoPWfPUUjzXHpcLdkVinfuyQR9-5QpSEGNwnk5_wGEbbek15V6N0JcAZw2viT0d6_8mwu8LAD2LtAxlCo2T1UDy8sGFv73W99nJ1wkaXGc4yucG186VMt_Xe8rINmaFPuyV61VEOu2vrypA9cqQ.V0TBTM2yOgqsvNxn0xb3rHBY4LzojsKwWwne40ZEvCY%26dib_tag%3Dse%26keywords%3Dguitar%26qid%3D1718799274%26sr%3D8-1-spons%26sp_csd%3Dd2lkZ2V0TmFtZT1zcF9hdGY%26psc%3D1', 'https://www.amazon.in/sspa/click?ie=UTF8&spc=MTo1NjIyODUyNDg2OTI3MTcwOjE3MTg3OTkyNzQ6c3BfYXRmOjIwMDk2NjA4NzUwNDk4OjowOjo&url=%2FKadence-Frontier-Acoustic-Guitar-Strings%2Fdp%2FB01GDZ46AA%2Fref%3Dsr_1_2_sspa%3Fdib%3DeyJ2IjoiMSJ9.H_dE0w8OHcmESxseNpLSv2KJQzpOhYBPQuvVEAHBow0jXCjOKKkLHAIV5Vm788nEVgS7X-PNTDnqOJ6rU8gbTjbKIEU0GlkBJardajM_Nxul_zYMIpU6j37pfjHvh5ZHPVH6i9Nm97xp1FmrlYL3tKwNwoPWfPUUjzXHpcLdkVinfuyQR9-5QpSEGNwnk5_wGEbbek15V6N0JcAZw2viT0d6_8mwu8LAD2LtAxlCo2T1UDy8sGFv73W99nJ1wkaXGc4yucG186VMt_Xe8rINmaFPuyV61VEOu2vrypA9cqQ.V0TBTM2yOgqsvNxn0xb3rHBY4LzojsKwWwne40ZEvCY%26dib_tag%3Dse%26keywords%3Dguitar%26qid%3D1718799274%26sr%3D8-2-spons%26sp_csd%3Dd2lkZ2V0TmFtZT1zcF9hdGY%26psc%3D1']\n",
      "['Kadence', 'B078GTJP5Y']\n",
      "['Kadence rosewood Guitar Frontier Series, Electric Acoustic Black Guitar With EQ, Die Cast Keys, Set Of Strings, Strap, Picks And Bag (Black EQ, Electric Acoustic)', 'Kadence Frontier guitar with Online Guitar learning course , Wine Red Acoustic Guitar with Die Cast Keys, Set of Strings, Strap, Picks and Bag (Wine Red, Acoustic)']\n",
      "['4,899', '4,899']\n",
      "['7 days Replacement', '7 days Replacement']\n",
      "['Monday, 1 July', 'Saturday, 22 June']\n",
      "['Monday, 1 July', 'Saturday, 22 June']\n"
     ]
    }
   ],
   "source": [
    "urls = []\n",
    "brand = []\n",
    "product_name = []\n",
    "price = []\n",
    "return_ = []\n",
    "expected = []\n",
    "available = []\n",
    "for i in range(3):\n",
    "    url = driver.find_elements(By.XPATH,'//h2[@ class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-4\"]/a')[:3]\n",
    "    for i in url:\n",
    "        url = i.get_attribute('href')\n",
    "        urls.append(url)\n",
    "    for url in urls:\n",
    "        driver.get(url)\n",
    "        \n",
    "        #for brand\n",
    "        try:\n",
    "            brand_ = driver.find_elements(By.XPATH,\"//table[@class='a-keyvalue prodDetTable']/tbody/tr[1]/td\")\n",
    "            for i in brand_:\n",
    "                brand.append(i.text)\n",
    "        except NoSuchElementException:\n",
    "            brand.append('-')\n",
    "\n",
    "        #for product name\n",
    "        try:\n",
    "            product = driver.find_elements(By.XPATH,'//span[@class=\"a-size-large product-title-word-break\"]')\n",
    "            for i in product:\n",
    "                product_name.append(i.text)\n",
    "        except NoSuchElementException:\n",
    "            product_name.append('-')\n",
    "\n",
    "        #for price\n",
    "        try:\n",
    "            price_ = driver.find_elements(By.XPATH,'//span [@class=\"a-price aok-align-center reinventPricePriceToPayMargin priceToPay\"]/span/span[2]')\n",
    "            for i in price_:\n",
    "                price.append(i.text)\n",
    "        except NoSuchElementException:\n",
    "            price.append('-')\n",
    "\n",
    "        #for return\n",
    "        try:\n",
    "            returns = driver.find_elements(By.XPATH,'/html/body/div[2]/div/div[5]/div[3]/div[4]/div[25]/div[2]/div/div/div/div[2]/div/ol/li[3]/div/span/div[2]/span')\n",
    "            for i in returns:\n",
    "                return_.append(i.text)\n",
    "        except NoSuchElementException:\n",
    "            return_.append('-')\n",
    "\n",
    "        #expected\n",
    "        try:\n",
    "            expected_ = driver.find_elements(By.XPATH,'/html/body/div[2]/div/div[5]/div[3]/div[1]/div[4]/div/div[1]/div/div/div/form/div/div/div/div/div[4]/div/div[3]/div[10]/div[1]/div/div/div/span/span[1]')\n",
    "            for i in expected_:\n",
    "                expected.append(i.text)\n",
    "        except NoSuchElementException:\n",
    "            expected.append('-')\n",
    "\n",
    "        #available\n",
    "        try:\n",
    "            available_ = driver.find_elements(By.XPATH,'/html/body/div[2]/div/div[5]/div[3]/div[1]/div[4]/div/div[1]/div/div/div/form/div/div/div/div/div[4]/div/div[3]/div[10]/div[1]/div/div/div/span/span[1]')\n",
    "            for i in available_:\n",
    "                available.append(i.text)\n",
    "        except NoSuchElementException:\n",
    "            available.append('-')\n",
    "\n",
    "print(urls[0:2])\n",
    "print(brand[:2])\n",
    "print(product_name[:2])\n",
    "print(price[:2])\n",
    "print(return_[:2])\n",
    "print(expected[:2])\n",
    "print(available[:2])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "549ed51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "18\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(urls))\n",
    "print(len(brand))\n",
    "print(len(product_name))\n",
    "print(len(price))\n",
    "print(len(return_))\n",
    "print(len(expected))\n",
    "print(len(available)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2ba15b41",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (9) does not match length of index (18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({})\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBrand\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m brand\n\u001b[1;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct Name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m product_name\n\u001b[0;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m price\n\u001b[0;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReturn/Replace\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m return_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3948\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3949\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3950\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item(key, value)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4134\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4135\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4136\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4141\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4143\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[0;32m   4145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4146\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4147\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4148\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4149\u001b[0m     ):\n\u001b[0;32m   4150\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4151\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4870\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (9) does not match length of index (18)"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df['Brand'] = brand\n",
    "df['Product Name'] = product_name\n",
    "df['Price'] = price\n",
    "df['Return/Replace'] = return_\n",
    "df['Expected Delivery'] = expected\n",
    "df['Availability'] = available\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36d7887",
   "metadata": {},
   "source": [
    "# 3. Write a python program to access the search bar and search button on images.google.com and scrape 10\n",
    "images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "228acb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping images for: fruits\n",
      "Found 0 images for fruits\n",
      "Scraping images for: cars\n",
      "Found 0 images for cars\n",
      "Scraping images for: Machine Learning\n",
      "Found 0 images for Machine Learning\n",
      "Scraping images for: Guitar\n",
      "Found 0 images for Guitar\n",
      "Scraping images for: Cakes\n",
      "Found 0 images for Cakes\n",
      "\n",
      "Images for fruits:\n",
      "\n",
      "Images for cars:\n",
      "\n",
      "Images for Machine Learning:\n",
      "\n",
      "Images for Guitar:\n",
      "\n",
      "Images for Cakes:\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "# Function to initialize the WebDriver\n",
    "def init_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--disable-infobars\")\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    options.add_argument(\"--disable-popup-blocking\")\n",
    "    options.add_argument(\"--incognito\")\n",
    "    # Do not add the headless argument to run in normal mode\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "# Function to search and scrape image URLs\n",
    "def scrape_images(driver, search_query, num_images=10):\n",
    "    search_url = \"https://images.google.com/\"\n",
    "    driver.get(search_url)\n",
    "    \n",
    "    # Locate the search bar, input the query, and perform the search\n",
    "    search_bar = driver.find_element(By.NAME, 'q')\n",
    "    search_bar.send_keys(search_query)\n",
    "    search_bar.send_keys(Keys.RETURN)\n",
    "    \n",
    "    time.sleep(2)  # Allow time for the search results to load\n",
    "    \n",
    "    # Scroll to load more images\n",
    "    for _ in range(2):\n",
    "        driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight)\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Locate the image elements and extract the URLs\n",
    "    image_elements = driver.find_elements(By.XPATH, '//img[@class=\"rg_i Q4LuWd\"]')[:num_images]\n",
    "    image_urls = []\n",
    "    for img in image_elements:\n",
    "        try:\n",
    "            img.click()\n",
    "            time.sleep(1)  # Allow time for the image to load in the preview pane\n",
    "            large_image = driver.find_element(By.XPATH, '//img[@class=\"n3VNCb\"]')\n",
    "            image_url = large_image.get_attribute('src')\n",
    "            if image_url.startswith('http'):\n",
    "                image_urls.append(image_url)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not get image URL for {search_query}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return image_urls\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = init_driver()\n",
    "\n",
    "# Keywords to search\n",
    "keywords = ['fruits', 'cars', 'Machine Learning', 'Guitar', 'Cakes']\n",
    "\n",
    "# Dictionary to store image URLs for each keyword\n",
    "images_dict = {}\n",
    "\n",
    "# Scrape images for each keyword\n",
    "for keyword in keywords:\n",
    "    print(f\"Scraping images for: {keyword}\")\n",
    "    images_dict[keyword] = scrape_images(driver, keyword, num_images=10)\n",
    "    print(f\"Found {len(images_dict[keyword])} images for {keyword}\")\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Print the results\n",
    "for keyword, image_urls in images_dict.items():\n",
    "    print(f\"\\nImages for {keyword}:\")\n",
    "    for url in image_urls:\n",
    "        print(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e19073",
   "metadata": {},
   "source": [
    "# Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com\n",
    "and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand\n",
    "Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”,\n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the\n",
    "details is missing then replace it by “- “. Save your results in a dataframe and CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3dca8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "92f589a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=driver.find_element(By.XPATH,'//*[@id=\"container\"]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/div/input')\n",
    "search_bar.send_keys(\"smartphone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "efe98f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.XPATH,'//*[@id=\"container\"]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/button')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "fd8be031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.flipkart.com/motorola-g34-5g-ocean-green-128-gb/p/itm6b1a33b9d9191?pid=MOBGUFK4TZ2CJYHJ&lid=LSTMOBGUFK4TZ2CJYHJPBUF6M&marketplace=FLIPKART&q=smartphone&store=tyy%2F4io&spotlightTagId=BestsellerId_tyy%2F4io&srno=s_1_1&otracker=search&otracker1=search&fm=Search&iid=3bfa628d-15b6-4290-9e02-4dad483fe0b5.MOBGUFK4TZ2CJYHJ.SEARCH&ppt=sp&ppn=sp&ssid=e3s24yz5io0000001718875637390&qH=1036ba3c4ed2c021',\n",
       " 'https://www.flipkart.com/samsung-galaxy-f14-5g-omg-black-128-gb/p/itmae94033406fb2?pid=MOBGNBFNE6KGXCCR&lid=LSTMOBGNBFNE6KGXCCRXLTXS7&marketplace=FLIPKART&q=smartphone&store=tyy%2F4io&srno=s_1_2&otracker=search&otracker1=search&fm=organic&iid=3bfa628d-15b6-4290-9e02-4dad483fe0b5.MOBGNBFNE6KGXCCR.SEARCH&ppt=hp&ppn=homepage&ssid=e3s24yz5io0000001718875637390&qH=1036ba3c4ed2c021']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list=[]\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"tUxRFH\"]/a'):\n",
    "    url_list.append(i.get_attribute(\"href\"))\n",
    "url_list[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bea23e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "for a in url_list:\n",
    "    driver.get(a)\n",
    "    \n",
    "    #brand\n",
    "    brand1 = driver.find_elements(By.XPATH,'//span[@class=\"VU-ZEz\"]')\n",
    "    for i in brand1:\n",
    "         brand.append(i.text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "daa49e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "77cbc9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3bba80d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone = []\n",
    "for a in url_list:\n",
    "    driver.get(a)\n",
    "    \n",
    "    #phone name\n",
    "    phone_ = driver.find_elements(By.XPATH,'//span[@class=\"VU-ZEz\"]')\n",
    "    for i in phone_:\n",
    "        phone.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "60167561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "76def9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = []\n",
    "for a in url_list:\n",
    "    driver.get(a)\n",
    "    \n",
    "    #phone name\n",
    "    try:\n",
    "        color_ = driver.find_elements(By.XPATH,'//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div/div[1]/table/tbody/tr[4]/td[2]/ul/li')\n",
    "        for i in color_:\n",
    "            color.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        color.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c21f989a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "63ed88c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ocean Green',\n",
       " 'OMG Black',\n",
       " 'GOAT Green',\n",
       " 'Ice Blue',\n",
       " 'Power Black',\n",
       " 'B.A.E. Purple',\n",
       " 'Charcoal Black',\n",
       " 'Pastel Blue',\n",
       " 'Mint Green',\n",
       " 'Ice Lilac',\n",
       " 'Pastel Green',\n",
       " 'Satin Blue',\n",
       " 'Pearl Blue',\n",
       " 'Matte Black',\n",
       " 'Starfrost White',\n",
       " 'Twilight Purple',\n",
       " 'Mint Green',\n",
       " 'Concord Black',\n",
       " 'Woodland Green',\n",
       " 'Twilight Purple']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7b96866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ram = []\n",
    "for a in url_list:\n",
    "    driver.get(a)\n",
    "    \n",
    "    #phone name\n",
    "    try:\n",
    "        ram_ = driver.find_elements(By.XPATH,'//li[contains(text(),\"RAM\")]/span')\n",
    "        for i in ram_:\n",
    "            ram.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        ram.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d952f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "rom = []\n",
    "for b in url_list:\n",
    "    driver.get(b)\n",
    "    \n",
    "    #Rom\n",
    "    try:\n",
    "        rom_ = driver.find_elements(By.XPATH,'//li[@class=\"_21lJbe\"]')\n",
    "        for j in rom_:\n",
    "            rom.append(j.text)\n",
    "    except NoSuchElementException:\n",
    "        rom.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e05b9738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import urllib.request\n",
    "import os # to create directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "944d8459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Rank, Name, Net Worth, Age, Citizenship, Source, Industry]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# URL of the Forbes billionaires page\n",
    "url = \"https://www.forbes.com/billionaires/\"\n",
    "\n",
    "# Open the URL\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load completely\n",
    "time.sleep(5)\n",
    "\n",
    "# Lists to store the data\n",
    "ranks = []\n",
    "names = []\n",
    "net_worths = []\n",
    "ages = []\n",
    "citizenships = []\n",
    "sources = []\n",
    "industries = []\n",
    "\n",
    "# Scroll to the bottom of the page to load all data\n",
    "SCROLL_PAUSE_TIME = 2\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    # Scroll down to the bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    \n",
    "    # Wait to load the page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    \n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "# Extract data from the page\n",
    "billionaires = driver.find_elements(By.XPATH, '//div[@data-type=\"table-row\"]')\n",
    "\n",
    "for billionaire in billionaires:\n",
    "    try:\n",
    "        rank = billionaire.find_element(By.XPATH, './/div[contains(@class, \"rank\")]').text\n",
    "    except:\n",
    "        rank = '-'\n",
    "    try:\n",
    "        name = billionaire.find_element(By.XPATH, './/div[contains(@class, \"personName\")]').text\n",
    "    except:\n",
    "        name = '-'\n",
    "    try:\n",
    "        net_worth = billionaire.find_element(By.XPATH, './/div[contains(@class, \"netWorth\")]').text\n",
    "    except:\n",
    "        net_worth = '-'\n",
    "    try:\n",
    "        age = billionaire.find_element(By.XPATH, './/div[contains(@class, \"age\")]').text\n",
    "    except:\n",
    "        age = '-'\n",
    "    try:\n",
    "        citizenship = billionaire.find_element(By.XPATH, './/div[contains(@class, \"countryOfCitizenship\")]').text\n",
    "    except:\n",
    "        citizenship = '-'\n",
    "    try:\n",
    "        source = billionaire.find_element(By.XPATH, './/div[contains(@class, \"source\")]').text\n",
    "    except:\n",
    "        source = '-'\n",
    "    try:\n",
    "        industry = billionaire.find_element(By.XPATH, './/div[contains(@class, \"category\")]').text\n",
    "    except:\n",
    "        industry = '-'\n",
    "    \n",
    "    ranks.append(rank)\n",
    "    names.append(name)\n",
    "    net_worths.append(net_worth)\n",
    "    ages.append(age)\n",
    "    citizenships.append(citizenship)\n",
    "    sources.append(source)\n",
    "    industries.append(industry)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "data = {\n",
    "    'Rank': ranks,\n",
    "    'Name': names,\n",
    "    'Net Worth': net_worths,\n",
    "    'Age': ages,\n",
    "    'Citizenship': citizenships,\n",
    "    'Source': sources,\n",
    "    'Industry': industries\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to a CSV file (optional)\n",
    "df.to_csv('forbes_billionaires.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c34c193b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Hostel Name, Distance from City Centre, Rating, Total Reviews, Overall Reviews, Privates from Price, Dorms from Price, Facilities, Property Description]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# # Function to initialize the WebDriver\n",
    "# def init_driver():\n",
    "#     options = webdriver.ChromeOptions()\n",
    "#     options.add_argument(\"--disable-infobars\")\n",
    "#     options.add_argument(\"--disable-extensions\")\n",
    "#     options.add_argument(\"--disable-popup-blocking\")\n",
    "#     options.add_argument(\"--incognito\")\n",
    "#     options.add_argument(\"--headless\")\n",
    "#     driver = webdriver.Chrome(options=options)\n",
    "#     return driver\n",
    "\n",
    "# Function to extract hostel data\n",
    "def extract_hostel_data(driver):\n",
    "    hostels = driver.find_elements(By.XPATH, '//div[@class=\"property\"]')\n",
    "\n",
    "    hostel_names = []\n",
    "    distances = []\n",
    "    ratings = []\n",
    "    total_reviews = []\n",
    "    overall_reviews = []\n",
    "    private_prices = []\n",
    "    dorm_prices = []\n",
    "    facilities_list = []\n",
    "    descriptions = []\n",
    "\n",
    "    for hostel in hostels:\n",
    "        # Hostel name\n",
    "        try:\n",
    "            name = hostel.find_element(By.XPATH, '/html/body/div[3]/div/div/div[2]/div[2]/div[1]/div/div/div[5]/div[1]/a/a/div[2]/div[1]/div[2]/span').text\n",
    "        except:\n",
    "            name = ''\n",
    "        hostel_names.append(name)\n",
    "\n",
    "        # Distance from city centre\n",
    "        try:\n",
    "            distance = hostel.find_element(By.XPATH, './/span[@class=\"distance-description\"]').text\n",
    "        except:\n",
    "            distance = ''\n",
    "        distances.append(distance)\n",
    "\n",
    "        # Rating\n",
    "        try:\n",
    "            rating = hostel.find_element(By.XPATH, './/div[@class=\"score orange big\"]').text\n",
    "        except:\n",
    "            rating = ''\n",
    "        ratings.append(rating)\n",
    "\n",
    "        # Total reviews\n",
    "        try:\n",
    "            reviews = hostel.find_element(By.XPATH, './/div[@class=\"reviews\"]').text\n",
    "        except:\n",
    "            reviews = ''\n",
    "        total_reviews.append(reviews)\n",
    "\n",
    "        # Overall reviews\n",
    "        try:\n",
    "            overall = hostel.find_element(By.XPATH, './/div[@class=\"keyword\"]/span').text\n",
    "        except:\n",
    "            overall = ''\n",
    "        overall_reviews.append(overall)\n",
    "\n",
    "        # Prices\n",
    "        try:\n",
    "            private_price = hostel.find_element(By.XPATH, './/div[@class=\"price privates\"]').text\n",
    "        except:\n",
    "            private_price = ''\n",
    "        private_prices.append(private_price)\n",
    "\n",
    "        try:\n",
    "            dorm_price = hostel.find_element(By.XPATH, './/div[@class=\"price dorms\"]').text\n",
    "        except:\n",
    "            dorm_price = ''\n",
    "        dorm_prices.append(dorm_price)\n",
    "\n",
    "        # Facilities\n",
    "        try:\n",
    "            facilities = hostel.find_element(By.XPATH, './/div[@class=\"facilities-label\"]').text\n",
    "        except:\n",
    "            facilities = ''\n",
    "        facilities_list.append(facilities)\n",
    "\n",
    "        # Property description\n",
    "        try:\n",
    "            description = hostel.find_element(By.XPATH, './/div[@class=\"rating-friends-summary\"]').text\n",
    "        except:\n",
    "            description = ''\n",
    "        descriptions.append(description)\n",
    "\n",
    "    return {\n",
    "        'Hostel Name': hostel_names,\n",
    "        'Distance from City Centre': distances,\n",
    "        'Rating': ratings,\n",
    "        'Total Reviews': total_reviews,\n",
    "        'Overall Reviews': overall_reviews,\n",
    "        'Privates from Price': private_prices,\n",
    "        'Dorms from Price': dorm_prices,\n",
    "        'Facilities': facilities_list,\n",
    "        'Property Description': descriptions\n",
    "    }\n",
    "\n",
    "# URL of the Hostelworld page for London hostels\n",
    "url = \"https://www.hostelworld.com/hostels/London\"\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = init_driver()\n",
    "\n",
    "# Open the Hostelworld page\n",
    "driver.get(url)\n",
    "\n",
    "# Allow time for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Extract the hostel data\n",
    "hostel_data = extract_hostel_data(driver)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(hostel_data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to a CSV file (optional)\n",
    "df.to_csv('london_hostels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "913713a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "23744dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.hostelworld.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e3461b7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_bar = driver.find_element(By.XPATH,'/html/body/div[3]/div/div[2]/main/header/div/div[2]/div[1]/div[3]/div/div/div[2]/div/div[1]/div/div[1]/div/div/div[2]/label/input')\n",
    "search_bar.send_keys('London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "15bcde1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "click = driver.find_element(By.ID,'3')\n",
    "click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2c84fd47",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: element click intercepted: Element <button data-v-74f29db0=\"\" data-v-42f760f2=\"\" class=\"btn-content\" type=\"button\">...</button> is not clickable at point (1186, 331). Other element would receive the click: <img alt=\"Get the App. QR\" width=\"72\" height=\"72\" class=\"qr-white\" loading=\"lazy\" src=\"https://a.hwstatic.com/image/upload/f_auto,q_auto,h_72/v1712750845/pwa/web-to-apps-qrcode.svg\" data-v-28a2c656=\"\">\n  (Session info: chrome=125.0.6422.176)\nStacktrace:\n\tGetHandleVerifier [0x00007FF7C1F31F52+60322]\n\t(No symbol) [0x00007FF7C1EACEC9]\n\t(No symbol) [0x00007FF7C1D67EBA]\n\t(No symbol) [0x00007FF7C1DBF32E]\n\t(No symbol) [0x00007FF7C1DBCCF2]\n\t(No symbol) [0x00007FF7C1DBA18B]\n\t(No symbol) [0x00007FF7C1DB9356]\n\t(No symbol) [0x00007FF7C1DAB491]\n\t(No symbol) [0x00007FF7C1DDC21A]\n\t(No symbol) [0x00007FF7C1DAADB6]\n\t(No symbol) [0x00007FF7C1DDC430]\n\t(No symbol) [0x00007FF7C1DFBC80]\n\t(No symbol) [0x00007FF7C1DDBFC3]\n\t(No symbol) [0x00007FF7C1DA9617]\n\t(No symbol) [0x00007FF7C1DAA211]\n\tGetHandleVerifier [0x00007FF7C22494AD+3301629]\n\tGetHandleVerifier [0x00007FF7C22936D3+3605283]\n\tGetHandleVerifier [0x00007FF7C2289450+3563680]\n\tGetHandleVerifier [0x00007FF7C1FE4326+790390]\n\t(No symbol) [0x00007FF7C1EB750F]\n\t(No symbol) [0x00007FF7C1EB3404]\n\t(No symbol) [0x00007FF7C1EB3592]\n\t(No symbol) [0x00007FF7C1EA2F9F]\n\tBaseThreadInitThunk [0x00007FFDD25E257D+29]\n\tRtlUserThreadStart [0x00007FFDD342AF28+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[170], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m search \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//div[@class=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mguests-footer\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]/button\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m search\u001b[38;5;241m.\u001b[39mclick()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:94\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(Command\u001b[38;5;241m.\u001b[39mCLICK_ELEMENT)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent\u001b[38;5;241m.\u001b[39mexecute(command, params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m: Message: element click intercepted: Element <button data-v-74f29db0=\"\" data-v-42f760f2=\"\" class=\"btn-content\" type=\"button\">...</button> is not clickable at point (1186, 331). Other element would receive the click: <img alt=\"Get the App. QR\" width=\"72\" height=\"72\" class=\"qr-white\" loading=\"lazy\" src=\"https://a.hwstatic.com/image/upload/f_auto,q_auto,h_72/v1712750845/pwa/web-to-apps-qrcode.svg\" data-v-28a2c656=\"\">\n  (Session info: chrome=125.0.6422.176)\nStacktrace:\n\tGetHandleVerifier [0x00007FF7C1F31F52+60322]\n\t(No symbol) [0x00007FF7C1EACEC9]\n\t(No symbol) [0x00007FF7C1D67EBA]\n\t(No symbol) [0x00007FF7C1DBF32E]\n\t(No symbol) [0x00007FF7C1DBCCF2]\n\t(No symbol) [0x00007FF7C1DBA18B]\n\t(No symbol) [0x00007FF7C1DB9356]\n\t(No symbol) [0x00007FF7C1DAB491]\n\t(No symbol) [0x00007FF7C1DDC21A]\n\t(No symbol) [0x00007FF7C1DAADB6]\n\t(No symbol) [0x00007FF7C1DDC430]\n\t(No symbol) [0x00007FF7C1DFBC80]\n\t(No symbol) [0x00007FF7C1DDBFC3]\n\t(No symbol) [0x00007FF7C1DA9617]\n\t(No symbol) [0x00007FF7C1DAA211]\n\tGetHandleVerifier [0x00007FF7C22494AD+3301629]\n\tGetHandleVerifier [0x00007FF7C22936D3+3605283]\n\tGetHandleVerifier [0x00007FF7C2289450+3563680]\n\tGetHandleVerifier [0x00007FF7C1FE4326+790390]\n\t(No symbol) [0x00007FF7C1EB750F]\n\t(No symbol) [0x00007FF7C1EB3404]\n\t(No symbol) [0x00007FF7C1EB3592]\n\t(No symbol) [0x00007FF7C1EA2F9F]\n\tBaseThreadInitThunk [0x00007FFDD25E257D+29]\n\tRtlUserThreadStart [0x00007FFDD342AF28+40]\n"
     ]
    }
   ],
   "source": [
    "search = driver.find_element(By.XPATH,'//div[@class=\"guests-footer\"]/button')\n",
    "search.click()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
